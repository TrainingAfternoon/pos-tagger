{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hidden Markov: POS Tagging\n",
    "Sam Keyser, Carter Shavitz, John Paul Bunn\n",
    "\n",
    "CS 2400 - Introduction to AI\n",
    "\n",
    "## Experiment\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import brown, treebank, conll2000\n",
    "\n",
    "# Download the requisite datasets\n",
    "nltk.download('treebank')\n",
    "nltk.download('brown')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "# Load datasets\n",
    "treebank_corpus = treebank.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(treebank_corpus)\n",
    "\n",
    "# Get a test X, y out of the corpus\n",
    "X, y = zip(*treebank_corpus[0])\n",
    "X = list(X)\n",
    "y = list(y)\n",
    "print('Sentence:', X)\n",
    "print('Tags:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Probability Counting\n",
    "Now that we've got a set of test sentences and tags, we need to start constructing the transition and emission probabilities. This count should be a function *N*, which is the length of the *N*-gram which we use to keep track of previous states up to the current one."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Playing around with Splitting Sentences into *N*-grams"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 3 # Default N-gram length\n",
    "start_tag ='!@#$%^&*()_+START+_)(*&^%$#@!' # some string of characters very unlikely to occur in the wild which we can use as start tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example of splitting using ngram from nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(*ngrams(X, N)) # Split up our X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Putting everything together to actuallt do some probability counting and an implementation of the viterbi algorithm for determining best walk through tag space, to label each observation/word.\n",
    "\n",
    "Hard coded to use N = 3 for simplicity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_tag ='START' # some string of characters very unlikely to occur in the wild which we can use as start tag\n",
    "end_tag = 'END'\n",
    "\n",
    "tag_words = []\n",
    "for sentence in brown.tagged_sents():\n",
    "    tag_words.append((start_tag, start_tag))\n",
    "    for word, tag in sentence:\n",
    "        tag_words.extend([(tag[:2], word)])\n",
    "    tag_words.append((end_tag, end_tag))\n",
    "\n",
    "cfd_tag_words = nltk.ConditionalFreqDist(tag_words)\n",
    "cpd_tag_words = nltk.ConditionalProbDist(cfd_tag_words, nltk.MLEProbDist)\n",
    "\n",
    "#print(\"The probability of an adjective (JJ) being 'smart' is\", cpd_tag_words[\"JJ\"].prob(\"smart\"))\n",
    "#print(\"The probability of a verb (VB) being 'try' is\", cpd_tag_words[\"VB\"].prob(\"try\"))\n",
    "\n",
    "tags = [tag for tag, word in tag_words]\n",
    "cfd_tags = nltk.ConditionalFreqDist(nltk.ngrams(tags, 2))\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)\n",
    "\n",
    "sample = \"Doctor Powers is a very neat chap\".split(' ')\n",
    "\n",
    "distinct_tags = set(tags)\n",
    "\n",
    "#print('The probability of DT occuring after NN is : ', cpd_tags[\"NN\"].prob(\"DT\"))\n",
    "#print('The probability of VB occuring after NN is : ', cpd_tags[\"NN\"].prob(\"VB\"))\n",
    "\n",
    "\n",
    "###\n",
    "# putting things together:\n",
    "# what is the probability of the tag sequence \"PP VB NN\" for the word sequence \"I love food\"?\n",
    "# It is\n",
    "# P(START) * P(PP|START) * P(I | PP) *\n",
    "#            P(VB | PP) * P(love | VB) *\n",
    "#            P(TO | VB) * P(food | NN) *\n",
    "#            P(END | VB)\n",
    "#\n",
    "# We leave aside P(START) for now.\n",
    "prob_tagsequence = cpd_tags[start_tag].prob(\"PP\") * cpd_tag_words[\"PP\"].prob(\"I\") * \\\n",
    "                   cpd_tags[\"PP\"].prob(\"VB\") * cpd_tag_words[\"VB\"].prob(\"love\") * \\\n",
    "                   cpd_tags[\"VB\"].prob(\"NN\") * cpd_tag_words[\"PP\"].prob(\"food\") * \\\n",
    "                   cpd_tags[\"NN\"].prob(end_tag)\n",
    "\n",
    "#print(\"The probability of sentence 'I love food' having the tag sequence 'START PP VB PP END' is : \", prob_tagsequence)\n",
    "\n",
    "viterbi_tag = {}\n",
    "viterbi_backpointer = {}\n",
    "\n",
    "for tag in distinct_tags:\n",
    "    if tag is start_tag:\n",
    "        continue\n",
    "    viterbi_tag[tag] = cpd_tags[start_tag].prob(tag) * cpd_tag_words[tag].prob(sample[0])\n",
    "   #print('viterbi_tag:', tag, viterbi_tag[tag])\n",
    "    viterbi_backpointer[tag] = start_tag\n",
    "\n",
    "viterbi_main = [viterbi_tag]\n",
    "backpointer_main = [viterbi_backpointer]\n",
    "\n",
    "curr_best = max(viterbi_tag.keys(), key=lambda tag: viterbi_tag[tag])\n",
    "\n",
    "#print(\"Word\", \"'\" + sample[0] + \"'\", \"current best two-tag sequence:\", viterbi_backpointer[curr_best], curr_best)\n",
    "\n",
    "#print(distinct_tags)\n",
    "for index in range(1, len(sample)):\n",
    "    curr_viterbi = {}\n",
    "    curr_backpointer = {}\n",
    "    prev_viterbi = viterbi_main[-1]\n",
    "\n",
    "    for tag in distinct_tags:\n",
    "        if tag is not start_tag:\n",
    "            prev_best = max(prev_viterbi.keys(), key=lambda prevtag: prev_viterbi[prevtag] * cpd_tags[prevtag].prob(tag) * cpd_tag_words[tag].prob(sample[index]))\n",
    "            #print('prev_best:', prev_best)\n",
    "\n",
    "            curr_viterbi[tag] = prev_viterbi[prev_best] * cpd_tags[prev_best].prob(tag) * cpd_tag_words[tag].prob(sample[index])\n",
    "            #print('curr_viterbi:', tag, curr_viterbi[tag])\n",
    "\n",
    "            curr_backpointer[tag] = prev_best\n",
    "\n",
    "    curr_best = max(curr_viterbi.keys(), key=lambda tag: curr_viterbi[tag])\n",
    "    #print(\"Word\", \"'\" + sample[index] + \"'\", \"current best two-tag sequence:\", curr_backpointer[curr_best], curr_best)\n",
    "\n",
    "    viterbi_main.append(curr_viterbi)\n",
    "    backpointer_main.append(curr_backpointer)\n",
    "\n",
    "prev_viterbi = viterbi_main[-1]\n",
    "prev_best = max(prev_viterbi.keys(), key=lambda prev_tag: prev_viterbi[prev_tag] * cpd_tags[prev_tag].prob(end_tag))\n",
    "prob_tag_seq = prev_viterbi[prev_best] * cpd_tags[prev_best].prob(end_tag)\n",
    "\n",
    "best_tag_seq = [end_tag, prev_best]\n",
    "backpointer_main.reverse()\n",
    "\n",
    "curr_best = prev_best\n",
    "for backpointer in backpointer_main:\n",
    "    best_tag_seq.append(backpointer[curr_best])\n",
    "    curr_best = backpointer[curr_best]\n",
    "\n",
    "best_tag_seq.reverse()\n",
    "print(\" \".join(sample))\n",
    "print('tags:', best_tag_seq[1:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}